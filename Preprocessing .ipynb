{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención de los datos\n",
    "import pandas as pd\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    hotel_df = pd.read_csv('files/hotel_bookings.csv')\n",
    "    x, y = hotel_df.shape\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "hotel_df.hist(bins=50, figsize=(20,15))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "hotel_df.boxplot(figsize=(38, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_df['is_canceled'].hist(bins=2)\n",
    "print(hotel_df['is_canceled'].value_counts())\n",
    "print(\"proporcion de clases: %s %%\" % (round(class_1 / class_2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a data set for train\n",
    "# 90/10\n",
    "import numpy as np\n",
    "from zlib import crc32\n",
    "\n",
    "def split_train_test(data, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    np.random.seed(1024)\n",
    "    train_set, test_set = split_train_test(hotel_df, 0.2)\n",
    "    train_set.to_csv('files/train.csv', index=False)\n",
    "    test_set.to_csv('files/test.csv', index=False)\n",
    "    print(len(train_set), len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA\n",
    "#Experimenting with atributes combiaitions\n",
    "#New atributes\n",
    "train_set = pd.read_csv('files/train.csv')\n",
    "train_set['total_guests'] = train_set['adults'] + train_set['children'] + train_set['babies']\n",
    "train_set['total_days'] = train_set['stays_in_week_nights'] + train_set['stays_in_weekend_nights']\n",
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_data = pd.DataFrame(train_set.loc[train_set[\"is_canceled\"] == 0][\"country\"].value_counts())\n",
    "#country_data.index.name = \"country\"\n",
    "country_data.rename(columns={\"country\": \"Number of Guests\"}, inplace=True)\n",
    "total_guests = country_data[\"Number of Guests\"].sum()\n",
    "country_data[\"Guests in %\"] = round(country_data[\"Number of Guests\"] / total_guests * 100, 2)\n",
    "country_data[\"country\"] = country_data.index\n",
    "country_data.loc[country_data[\"Guests in %\"] < 4, \"country\"] = \"Other\"\n",
    "\n",
    "# pie plot\n",
    "fig = px.pie(country_data,\n",
    "             values=\"Number of Guests\",\n",
    "             names=\"country\",\n",
    "             title=\"De que paises vienen la mayoria de los huespedes que si cancelaron\",\n",
    "             template=\"seaborn\")\n",
    "fig.update_traces(textposition=\"inside\", textinfo=\"value+percent+label\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "train_set = pd.read_csv('files/train.csv')\n",
    "\n",
    "train_set = train_set[train_set['country'] != 'PRT']\n",
    "\n",
    "country_data_cancelados = train_set.groupby(['country'])['is_canceled'].sum().reset_index().sort_values(by='is_canceled',ascending=False)\n",
    "country_data_cancelados['% de cancelados'] = round(country_data_cancelados['is_canceled'] / max(country_data_cancelados['is_canceled']) * 100, 2)\n",
    "\n",
    "\n",
    "guest_map = px.choropleth(country_data_cancelados,\n",
    "                    locations=country_data_cancelados['country'],\n",
    "                    color=country_data_cancelados[\"% de cancelados\"], \n",
    "                    hover_name=country_data_cancelados['country'], \n",
    "                    color_continuous_scale=px.colors.sequential.Reds,\n",
    "                    title=\"Países donde existen mas cancelaciones (se excluye a Portugal)\")\n",
    "guest_map.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Por mes\n",
    "meses_ordenados = ['January', \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "train_set['Mes'] = pd.Categorical(train_set['arrival_date_month'], categories=meses_ordenados, ordered=True)\n",
    "\n",
    "country_data_cancelados = train_set.groupby(['country','Mes'])['total_guests','is_canceled'].sum().reset_index().sort_values(by='Mes')\n",
    "country_data_cancelados['% de cancelados'] = round(country_data_cancelados['is_canceled']/ country_data_cancelados['total_guests'] * 100, 2)\n",
    "country_data_cancelados.dropna(inplace=True)\n",
    "country_data_cancelados = country_data_cancelados.reset_index()\n",
    "country_data_cancelados = country_data_cancelados.drop('index',axis=1)\n",
    "\n",
    "guest_map = px.choropleth(country_data_cancelados,\n",
    "                    locations=country_data_cancelados['country'],\n",
    "                    color=country_data_cancelados[\"total_guests\"], \n",
    "                    hover_name=country_data_cancelados['country'],\n",
    "                    animation_frame=\"Mes\",\n",
    "                    color_continuous_scale=px.colors.sequential.Reds,\n",
    "                    title=\"Origen por fecha de paises donde existen mas cancelaciones\")\n",
    "guest_map.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 2000\n",
    "\n",
    "guest_map.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting adults and children as paying guests only, not babies.\n",
    "import numpy as np\n",
    "train_set = pd.read_csv('files/train.csv')\n",
    "rhotel = train_set[train_set['hotel'] == 'Resort Hotel'].copy()\n",
    "chotel = train_set[train_set['hotel'] == 'City Hotel'].copy()\n",
    "\n",
    "rhotel.fillna(1, inplace=True)\n",
    "rhotel.replace(np.inf, 1, inplace=True)\n",
    "rhotel[\"adr_pp\"] = rhotel[\"adr\"] / (rhotel[\"adults\"] + rhotel[\"children\"])\n",
    "chotel.fillna(0, inplace=True)\n",
    "chotel.replace(np.inf, 0, inplace=True)\n",
    "chotel[\"adr_pp\"] = chotel[\"adr\"] / (chotel[\"adults\"] + chotel[\"children\"])\n",
    "\n",
    "room_prices_mothly = train_set[[\"hotel\", \"arrival_date_month\", \"adr_pp\"]].sort_values(\"arrival_date_month\")\n",
    "\n",
    "# order by month:\n",
    "ordered_months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \n",
    "          \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "room_prices_mothly[\"arrival_date_month\"] = pd.Categorical(room_prices_mothly[\"arrival_date_month\"], categories=ordered_months, ordered=True)\n",
    "\n",
    "# barplot with standard deviation:\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(x = \"arrival_date_month\", y=\"adr_pp\", hue=\"hotel\", data=room_prices_mothly, \n",
    "            hue_order = [\"City Hotel\", \"Resort Hotel\"], ci=\"sd\", size=\"hotel\", sizes=(2.5, 2.5))\n",
    "plt.title(\"Room price per night and person over the year\", fontsize=16)\n",
    "plt.xlabel(\"Month\", fontsize=16)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"Price [EUR]\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = train_set.corr()\n",
    "corr_matrix['is_canceled'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "atributes = ['lead_time', 'previous_cancellations', 'total_of_special_requests', 'required_car_parking_spaces', 'booking_changes']\n",
    "pd.plotting.scatter_matrix(train_set[atributes], figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.isnull().sum() / len(train_set) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparación de los datos\n",
    "#X_train = pd.read_csv('files/train.csv')\n",
    "X_train = train_set.drop('is_canceled', axis=1)\n",
    "y_train = train_set['is_canceled'].copy()\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num = X_train.select_dtypes(exclude=['object'])\n",
    "print(X_train_num.columns)\n",
    "#X_train_num[''].unique()\n",
    "X_train_num.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat = X_train.select_dtypes(include=['object', 'category'])\n",
    "atrs_cat = X_train_cat.columns\n",
    "atrs_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95512, 37) (95512,) (23878, 37) (23878,)\n"
     ]
    }
   ],
   "source": [
    "#Missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "#For standarization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#For work encode categorical atrubuts\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "#For do a best a work flow\n",
    "from sklearn.pipeline import Pipeline\n",
    "#Models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    ########################################################################\n",
    "    #Load our data sets\n",
    "    train_set = pd.read_csv('files/train.csv')\n",
    "    test_set = pd.read_csv('files/test.csv')\n",
    "    \n",
    "    #New atributes\n",
    "    \n",
    "    #Train\n",
    "    train_set['total_guests'] = train_set['adults'] + train_set['children'] + train_set['babies']\n",
    "    train_set['total_days'] = train_set['stays_in_week_nights'] + train_set['stays_in_weekend_nights']\n",
    "    #Test\n",
    "    test_set['total_guests'] = test_set['adults'] + test_set['children'] + test_set['babies']\n",
    "    test_set['total_days'] = test_set['stays_in_week_nights'] + test_set['stays_in_weekend_nights']\n",
    "    \n",
    "    #Preparing data for our model\n",
    "    \n",
    "    #Train\n",
    "    X_train = train_set.drop('is_canceled', axis=1)\n",
    "    y_train = train_set['is_canceled'].copy()\n",
    "    #Train\n",
    "    X_test = test_set.drop('is_canceled', axis=1)\n",
    "    y_test = test_set['is_canceled'].copy()\n",
    "    \n",
    "    #Cleaning data\n",
    "    \n",
    "    #Numerical atributs droped\n",
    "    atrs_n = ['arrival_date_year', 'arrival_date_day_of_month', 'stays_in_weekend_nights', 'stays_in_week_nights', 'adults', 'children', 'babies', 'company', 'agent', 'total_guests']\n",
    "    #Categorical atributs droped \n",
    "    atrs_cat = ['reservation_status', 'reservation_status_date', 'country', 'market_segment', 'distribution_channel', 'reserved_room_type', 'assigned_room_type']\n",
    "    atrs = atrs_cat + atrs_n\n",
    "    #Train\n",
    "    X_train = X_train.drop(atrs, axis=1)\n",
    "    #Test\n",
    "    X_test = X_test.drop(atrs, axis=1)\n",
    "    \n",
    "    #Encoding category type data\n",
    "    \n",
    "    #########\n",
    "    #Train\n",
    "    X_train_num = X_train.select_dtypes(exclude=['object', 'category']).columns\n",
    "    X_train_cat = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "    num_pipeline = Pipeline([\n",
    "    #('imputer', SimpleImputer(strategy=\"constant\")),\n",
    "    #('attribs_adder', CombinedAttributesAdder()), #Experimenting with atributes combinations\n",
    "    ('std', StandardScaler()),#std_scaler#Standarization\n",
    "    ])\n",
    "\n",
    "    num_attribs = X_train_num#For get numeric data\n",
    "    cat_attribs = X_train_cat#For category data\n",
    "    full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ]) \n",
    "    X_train = full_pipeline.fit_transform(X_train)\n",
    "    #########\n",
    "    #Test\n",
    "    X_test_num = X_test.select_dtypes(exclude=['object', 'category']).columns\n",
    "    X_test_cat = X_test.select_dtypes(include=['object', 'category']).columns\n",
    "    num_pipeline = Pipeline([\n",
    "    #('imputer', SimpleImputer(strategy=\"constant\")),\n",
    "    #('attribs_adder', CombinedAttributesAdder()), #Experimenting with atributes combinations\n",
    "    ('std', StandardScaler()),#std_scaler#Standarization\n",
    "    ])\n",
    "\n",
    "    num_attribs = X_test_num#For get numeric data\n",
    "    cat_attribs = X_test_cat#For category data\n",
    "    full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ]) \n",
    "    \n",
    "    X_test = full_pipeline.fit_transform(X_test)\n",
    "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "    \n",
    "    ########################################################################   \n",
    "    ####### Logit Regression ######\n",
    "    log_reg = LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
    "                    intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
    "                    multi_class='multinomial', n_jobs=-1, penalty='l2',\n",
    "                    random_state=42, solver='lbfgs', tol=0.000001, verbose=0,\n",
    "                    warm_start=False)\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    #y_predict = log_reg.predict(X_test)\n",
    "    #######acc = 0.7884244911634141\n",
    "   \n",
    "    #####################################################\n",
    "    #Decission TeeeClassifer\n",
    "    tree_clas = DecisionTreeClassifier(ccp_alpha=0.0000001, criterion='gini',\n",
    "                                       max_depth=33, max_features=9, max_leaf_nodes=None,\n",
    "                                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                       min_samples_leaf=1, min_samples_split=2,\n",
    "                                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                                       random_state=42, splitter='best')\n",
    "    tree_clas.fit(X_train, y_train)\n",
    "    #y_predict = tree_clas.predict(X_test)   \n",
    "    ######.86\n",
    "    #####################################################\n",
    "    ####### Decission RandomForestClassifier ######\n",
    "    forest_reg = RandomForestClassifier(n_estimators=292,\n",
    "                                        criterion='gini',\n",
    "                                        max_depth=32,\n",
    "                                        min_samples_split=2,\n",
    "                                        min_samples_leaf=1, \n",
    "                                        min_weight_fraction_leaf=0.0, \n",
    "                                        max_features=8, \n",
    "                                        max_leaf_nodes=None, \n",
    "                                        min_impurity_decrease=0.0, \n",
    "                                        min_impurity_split=None, \n",
    "                                        bootstrap=True, \n",
    "                                        oob_score=True, \n",
    "                                        n_jobs=-1, \n",
    "                                        random_state=42, \n",
    "                                        verbose=0, \n",
    "                                        warm_start=False, \n",
    "                                        class_weight=None, \n",
    "                                        ccp_alpha=0.000001, \n",
    "                                        max_samples=None, \n",
    "                                       )\n",
    "    forest_reg.fit(X_train, y_train)\n",
    "    #y_predict = rand_clas.predict(X_test)    \n",
    "    ######0.8546035024693207######\n",
    "    #####################################################\n",
    "    ###### Decission SVM ######\n",
    "    svm_clf = svm.SVC(C=1.0, break_ties=False, cache_size=800, class_weight=None, coef0=0.0,\n",
    "                        decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
    "                        max_iter=-1, probability=True, random_state=42, shrinking=True, tol=0.001,\n",
    "                        verbose=False)\n",
    "    svm_clf.fit(X_train, y_train)\n",
    "    #y_predict = svm_clas.predict(X_test)    \n",
    "    #######acc = 0.8045736304238565######\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate, cross_val_score\n",
    "\n",
    "# define models to test:\n",
    "base_models = [(\"DT_model\", DecisionTreeClassifier(random_state=42)),\n",
    "               (\"RF_model\", RandomForestClassifier(random_state=42,n_jobs=-1)),\n",
    "               (\"LR_model\", LogisticRegression(random_state=42,n_jobs=-1)),\n",
    "               #(\"XGB_model\", XGBClassifier(random_state=42, n_jobs=-1))\n",
    "              ]\n",
    "\n",
    "param_grid = {'n_estimators': [200, 500],\n",
    "              'max_features': ['auto', 'sqrt', 'log2'],\n",
    "              'max_depth' : [4,5,7],\n",
    "              'criterion' :['gini', 'entropy']\n",
    "             }\n",
    "forest_reg = RandomForestClassifier(random_state=1024, n_jobs=-1)\n",
    "grid_search = GridSearchCV(estimator=forest_reg, param_grid=param_grid, cv=5, verbose=True)\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "final_model = grid_search.best_estimator_\n",
    "y_predict = final_model.predict(X_test)\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "AUC_log_reg = roc_auc_score(y_test, y_predict_lr)\n",
    "AUC_tree_clas = roc_auc_score(y_test, y_predict_dt)\n",
    "AUC_rand_clas = roc_auc_score(y_test, y_predict_rf)\n",
    "AUC_svm_clas = roc_auc_score(y_test, y_predict_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "#Logistic Regresion\n",
    "y_pred_lr = log_reg.predict_proba(X_test_lr)[:, 1]\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_pred_lr)\n",
    "\n",
    "#Decission TeeeClassifer\n",
    "y_pred_dt = tree_clas.predict_proba(X_test_dt)[:,1]\n",
    "fpr_tree_clas, tpr_tree_clas, _ = roc_curve(y_test, y_pred_dt)\n",
    "\n",
    "#Decission RandomForestClassifier\n",
    "y_pred_rf = forest_reg.predict_proba(X_test_rf)[:,1]\n",
    "fpr_rand_clas, tpr_rand_clas, _ = roc_curve(y_test, y_pred_rf)\n",
    "\n",
    "#Decission SVM\n",
    "y_pred_svm_clas = svm_clf.predict_proba(X_test_svm)[:,1]\n",
    "fpr_svm_clas, tpr_svm_clas, _ = roc_curve(y_test, y_predict_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "plt.plot(fpr_lr, tpr_lr, label='Logistic Regression')\n",
    "plt.plot(fpr_tree_clas, tpr_tree_clas, label='Decission Tree')\n",
    "plt.plot(fpr_rand_clas, tpr_rand_clas, label='Random Forest')\n",
    "plt.plot(fpr_svm_clas, tpr_svm_clas, label='SVM')\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
