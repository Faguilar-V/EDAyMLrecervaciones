{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Preprocessing_RL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "8164YPFTVU3H",
        "colab_type": "code",
        "outputId": "7e1ab6ec-801c-4ee6-bbc6-7d16ab262aac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "#Missing values\n",
        "from sklearn.impute import SimpleImputer\n",
        "#For standarization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#For work encode categorical atrubuts\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "#For do a best a work flow\n",
        "from sklearn.pipeline import Pipeline\n",
        "#Models\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import fbeta_score\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "if __name__ == '__main__': \n",
        "    ########################################################################\n",
        "    #Load our data sets\n",
        "    train_set= pd.read_csv('/content/train.csv')\n",
        "    test_set = pd.read_csv('/content/test.csv')\n",
        "\n",
        "    #train_set=train_set.drop(['lead_time','agent'],axis='columns')\n",
        "    #test_set=test_set.drop(['lead_time','agent'],axis='columns')\n",
        "    \n",
        "    #New atributes\n",
        "    train_set.loc[(train_set.children == 'Transient'),'children']=0\n",
        "    #Train\n",
        "    train_set['total_guests'] = train_set['adults'] + train_set['children'].astype('float') + train_set['babies']\n",
        "    train_set['total_days'] = train_set['stays_in_week_nights'] + train_set['stays_in_weekend_nights']\n",
        "    #Test\n",
        "    test_set['total_guests'] = test_set['adults'] + test_set['children'] + test_set['babies']\n",
        "    test_set['total_days'] = test_set['stays_in_week_nights'] + test_set['stays_in_weekend_nights']\n",
        "    \n",
        "    #Preparing data for our model\n",
        "    \n",
        "    #Train\n",
        "    X_train = train_set.drop('is_canceled', axis=1)\n",
        "    y_train = train_set['is_canceled'].copy()\n",
        "    #Test\n",
        "    X_test = test_set.drop('is_canceled', axis=1)\n",
        "    y_test = test_set['is_canceled'].copy()\n",
        "    \n",
        "    #Cleaning data\n",
        "    \n",
        "    #Numerical atributs droped\n",
        "    atrs_n = ['arrival_date_year', 'arrival_date_day_of_month', 'stays_in_weekend_nights', 'stays_in_week_nights', 'adults', 'children', 'babies', 'company','agent']\n",
        "    #Categorical atributs droped \n",
        "    atrs_cat = ['reservation_status', 'reservation_status_date', 'country', 'market_segment', 'distribution_channel', 'reserved_room_type', 'assigned_room_type']\n",
        "    atrs = atrs_cat + atrs_n\n",
        "    #Train\n",
        "    X_train = X_train.drop(atrs, axis=1)\n",
        "    #Test\n",
        "    X_test = X_test.drop(atrs, axis=1)\n",
        "    print (X_test.columns)\n",
        "    \n",
        "    #Encoding category type data\n",
        "    \n",
        "    #########\n",
        "    #Train\n",
        "    X_train_num = X_train.select_dtypes(exclude=['object', 'category']).columns\n",
        "    X_train_cat = X_train.select_dtypes(include=['object', 'category']).columns\n",
        "    num_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy=\"mean\")),\n",
        "    ('std', StandardScaler()),#std_scaler#Standarization\n",
        "    ])\n",
        "\n",
        "    num_attribs = X_train_num#For get numeric data\n",
        "    cat_attribs = X_train_cat#For category data\n",
        "    full_pipeline = ColumnTransformer([\n",
        "    (\"num\", num_pipeline, num_attribs),\n",
        "    (\"cat\", OneHotEncoder(), cat_attribs),\n",
        "    ]) \n",
        "    X_train = full_pipeline.fit_transform(X_train)\n",
        "    #########\n",
        "    #Test\n",
        "    X_test_num = X_test.select_dtypes(exclude=['object', 'category']).columns\n",
        "    X_test_cat = X_test.select_dtypes(include=['object', 'category']).columns\n",
        "    num_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy=\"mean\")),\n",
        "    ('std', StandardScaler()),#std_scaler#Standarization\n",
        "    ])\n",
        "\n",
        "    num_attribs = X_test_num#For get numeric data\n",
        "    cat_attribs = X_test_cat#For category data\n",
        "    full_pipeline = ColumnTransformer([\n",
        "    (\"num\", num_pipeline, num_attribs),\n",
        "    (\"cat\", OneHotEncoder(), cat_attribs),\n",
        "    ]) \n",
        "    \n",
        "    X_test = full_pipeline.fit_transform(X_test)\n",
        "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "    \n",
        "    ########################################################################\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  res_values = method(rvalues)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Index(['hotel', 'lead_time', 'arrival_date_month', 'arrival_date_week_number',\n",
            "       'meal', 'is_repeated_guest', 'previous_cancellations',\n",
            "       'previous_bookings_not_canceled', 'booking_changes', 'deposit_type',\n",
            "       'days_in_waiting_list', 'customer_type', 'adr',\n",
            "       'required_car_parking_spaces', 'total_of_special_requests',\n",
            "       'total_guests', 'total_days'],\n",
            "      dtype='object')\n",
            "(107451, 38) (107451,) (11939, 38) (11939,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpKMVB5w-D_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Logistic Regression\n",
        "\n",
        "\"\"\"\n",
        "#--- Class balance ---#\n",
        "    0    67749\n",
        "    1    39702\n",
        "\"\"\"\n",
        "log_reg = LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
        "                intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
        "                multi_class='multinomial', n_jobs=-1, penalty='l2',\n",
        "                random_state=42, solver='lbfgs', tol=0.000001, verbose=0,\n",
        "                warm_start=False)\n",
        "log_reg.fit(X_train, y_train)\n",
        "y_predict = log_reg.predict(X_test)\n",
        "#0.7884244911634141\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIXPtDJ7VU3m",
        "colab_type": "code",
        "outputId": "35da9f39-7b6d-4099-9d26-651cf102d661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(accuracy_score(y_predict, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7884244911634141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7USHbzEErwLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}